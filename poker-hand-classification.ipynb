{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install fastai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.tabular import tabular_learner, TabularList, Categorify, Learner, accuracy\n",
    "from fastai.train import ShowGraph\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import random\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rc('figure', figsize=(12.5,5))\n",
    "plt.rc('font', size=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Set random seed**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_seed(seed_value, use_cuda=True):\n",
    "    np.random.seed(seed_value) # cpu vars\n",
    "    torch.manual_seed(seed_value) # cpu  vars\n",
    "    random.seed(seed_value) # Python\n",
    "    if use_cuda: \n",
    "        torch.cuda.manual_seed(seed_value)\n",
    "        torch.cuda.manual_seed_all(seed_value) # gpu vars\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_seed(123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Defining the Model Parameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'epochs': 800,\n",
    "    'bs': 128,\n",
    "    'layers': [20,20,20,20],\n",
    "    'wd': 0.0,\n",
    "    'ps': 0.0,\n",
    "    'emb_drop': 0.0,\n",
    "    'lr': 1e-01,\n",
    "    'use_GPU': False,\n",
    "    'n_folds': 5\n",
    "}\n",
    "\n",
    "data_dir = 'poker_hand_data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset():\n",
    "    train = pd.read_csv(data_dir + 'poker-hand-training.data', header=None)\n",
    "    test = pd.read_csv(data_dir + 'poker-hand-testing.data', header=None)\n",
    "\n",
    "    train.columns = ['S1','C1','S2','C2','S3','C3','S4','C4','S5','C5','Hand']\n",
    "    test.columns = ['S1','C1','S2','C2','S3','C3','S4','C4','S5','C5','Hand']\n",
    "    \n",
    "    print(f'Train shape:{train.shape}')\n",
    "    print(f'Test shape:{test.shape}')\n",
    "    \n",
    "    return (train, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Helper Functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_training_to_list(learn, train_losses:list, valid_losses:list, metrics:list):\n",
    "    nb_epochs=len(learn.recorder.val_losses) \n",
    "    iterations_per_epoch = len(learn.recorder.losses)//nb_epochs\n",
    "    for i in range(iterations_per_epoch-1,iterations_per_epoch*nb_epochs,iterations_per_epoch):\n",
    "        train_losses.append(learn.recorder.losses[i].numpy())\n",
    "    for i in range(nb_epochs):\n",
    "        metrics.append(learn.recorder.metrics[i][0].numpy())\n",
    "    valid_losses.extend(learn.recorder.val_losses)\n",
    "    return train_losses, valid_losses, metrics\n",
    "\n",
    "def add_fold_to_dataframe(train_losses:list, valid_losses:list, metrics:list, train_losses_df, valid_losses_df, metrics_df):\n",
    "    train_losses = pd.Series(train_losses)\n",
    "    valid_losses = pd.Series(valid_losses)\n",
    "    metrics = pd.Series(metrics)\n",
    "\n",
    "    train_losses_df = train_losses_df.append(train_losses, ignore_index=True)\n",
    "    valid_losses_df = valid_losses_df.append(valid_losses, ignore_index=True)\n",
    "    metrics_df = metrics_df.append(metrics, ignore_index=True)\n",
    "    return train_losses_df, valid_losses_df, metrics_df\n",
    "\n",
    "def get_avg_column_val(df):\n",
    "    averages = list()\n",
    "    for i in range(len(df.columns)):\n",
    "        averages.append(df[i].mean())\n",
    "    return averages\n",
    "\n",
    "def kfold_results(train_losses_df, valid_losses_df, metrics_df):\n",
    "    avg_train_losses = get_avg_column_val(train_losses_df)\n",
    "    avg_valid_losses = get_avg_column_val(valid_losses_df)\n",
    "    avg_metrics = get_avg_column_val(metrics_df)\n",
    "    epochs = np.arange(len(avg_train_losses))\n",
    "    results_lists = {'epochs': epochs, 'train_loss': avg_train_losses, 'valid_loss': avg_valid_losses, 'accuracy': avg_metrics}\n",
    "    results = pd.DataFrame(results_lists)\n",
    "    return results\n",
    "\n",
    "def print_kfold_results(results):\n",
    "    total_epochs = results.shape[0]\n",
    "    last_accuracy = results.iloc[-1]['accuracy']\n",
    "    last_train_loss = results.iloc[-1]['train_loss']\n",
    "    last_valid_loss = results.iloc[-1]['valid_loss']\n",
    "    print('-'*20, '\\n', 'Overall results (averaged over folds)'); print('-'*20, '\\n')\n",
    "    print(f'Number of epochs: {total_epochs}')\n",
    "    print(f'Accuracy: {last_accuracy}')\n",
    "    print(f'Train loss: {last_train_loss}')\n",
    "    print(f'Valid loss: {last_valid_loss}')\n",
    "    print(results)\n",
    "    #print(tabulate(results, headers='keys', tablefmt='fancy_grid', showindex=False))\n",
    "\n",
    "def plot_kfold_results(results, bs):\n",
    "    nb_epochs=results.shape[0]\n",
    "    fig,ax = plt.subplots(2,1,figsize=(8,12))\n",
    "    fig.suptitle('Results - averaged over folds')\n",
    "    ax[0].plot(list(range(nb_epochs)), results['train_loss'], label='Training loss')\n",
    "    ax[0].plot(list(range(nb_epochs)), results['valid_loss'], label='Validation loss')\n",
    "    ax[0].set_xlabel('Epoch')\n",
    "    ax[0].xaxis.set_ticks(np.arange(0,nb_epochs,1))\n",
    "    ax[0].set_ylabel('Loss')\n",
    "    ax[0].legend(loc='upper right')\n",
    "    ax[1].plot(list(range(nb_epochs)),results['accuracy'])\n",
    "    ax[1].xaxis.set_ticks(np.arange(0,nb_epochs,1))\n",
    "    ax[1].set_xlabel('Epoch')\n",
    "    ax[1].set_ylabel('Accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_metrics(learner:Learner, dep_var, test_df, procs=None, bs=64):\n",
    "    '''Function to validate trained model on test set'''\n",
    "    \n",
    "    #get continious and categorical variable names from the learner\n",
    "    cat_names=learner.data.cat_names\n",
    "    cont_names=learner.data.cont_names\n",
    "    \n",
    "    #create fastai Databunch that holds the data in batches for the algorithm\n",
    "    data = (TabularList.from_df(test_df, cat_names=cat_names, cont_names=cont_names, procs=preProcc)\n",
    "                    .split_none()\n",
    "                    .label_from_df(dep_var)\n",
    "                    .databunch(bs=bs))\n",
    "    data.valid_dl = data.train_dl\n",
    "    \n",
    "    #validate algorithm\n",
    "    learner.data.valid_dl = data.valid_dl\n",
    "    return learner.validate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_model_cv(df):\n",
    "    '''\n",
    "    Function to fit model on training data with cross-validation\n",
    "    \n",
    "    Parameters:\n",
    "    df: training data as pandas DataFrame\n",
    "    \n",
    "    Returns cross-validation results\n",
    "    '''\n",
    "    \n",
    "    df=df.copy(); use_GPU=params['use_GPU'] \n",
    "    \n",
    "    #tracking variables\n",
    "    train_losses_df = pd.DataFrame()\n",
    "    valid_losses_df = pd.DataFrame()\n",
    "    metrics_df = pd.DataFrame()\n",
    "    \n",
    "    #prepare cross validation\n",
    "    random_seed(123)\n",
    "    stratified_k_fold = StratifiedKFold(params['n_folds'], shuffle=True, random_state=1)\n",
    "    \n",
    "    #iterate over folds\n",
    "    for iteration_idx, (train_idxs, valid_idxs) in enumerate(stratified_k_fold.split(df.loc[:,df.columns!=dep_var[0]], df[dep_var])):\n",
    "        fold_idx = iteration_idx+1\n",
    "        print('-'*20, '\\n', f'> Fold: {fold_idx}'); print('-'*20)\n",
    "        \n",
    "        #tracking variables\n",
    "        train_losses = list()\n",
    "        valid_losses = list()\n",
    "        metrics = list()\n",
    "        \n",
    "        #create fastai Databunch that holds the data in batches for the algorithm\n",
    "        random_seed(123)\n",
    "        data = (TabularList.from_df(df, cat_names=cat_vars, procs=preProcc)\n",
    "                            .split_by_idx(valid_idxs)\n",
    "                            .label_from_df(dep_var)\n",
    "                            .databunch(bs=params['bs']))\n",
    "        \n",
    "        #create fastai learner that handles the training and prediction of the neural network\n",
    "        learn = tabular_learner(data, layers=params['layers'], metrics=accuracy, ps=params['ps'], emb_szs=emb_szs, emb_drop=params['emb_drop'], callback_fns=[ShowGraph])\n",
    "        if use_GPU:\n",
    "            learn = learn.to_fp16()\n",
    "            \n",
    "        #fit neural network\n",
    "        random_seed(123)\n",
    "        learn.fit_one_cycle(params['epochs'], max_lr=params['lr'], wd=params['wd'])\n",
    "        \n",
    "        #track fold\n",
    "        train_losses, valid_losses, metrics = add_training_to_list(learn, train_losses, valid_losses, metrics)\n",
    "        \n",
    "        #add fold to dataframe\n",
    "        train_losses_df, valid_losses_df, metrics_df = add_fold_to_dataframe(train_losses, valid_losses, metrics, train_losses_df, valid_losses_df, metrics_df)\n",
    "    \n",
    "    \n",
    "    #show results    \n",
    "    results = kfold_results(train_losses_df, valid_losses_df, metrics_df)  \n",
    "    print_kfold_results(results)\n",
    "    plot_kfold_results(results, params['bs'])\n",
    "\n",
    "    return results\n",
    "\n",
    "def fit_model_test(train, test):\n",
    "    '''\n",
    "    Function to fit model on complete training data and evaluate on test data\n",
    "    \n",
    "    Parameters:\n",
    "    train: training data as pandas DataFrame\n",
    "    test: testing data as pandas DataFrame\n",
    "    \n",
    "    Returns trained fastai Learner\n",
    "    '''\n",
    "    train=train.copy(); test=test.copy(); use_GPU=params['use_GPU'] \n",
    "\n",
    "    #create fastai Databunch that holds the data in batches for the algorithm\n",
    "    random_seed(123)\n",
    "    data = (TabularList.from_df(train, cat_names=cat_vars, procs=preProcc)\n",
    "                    .split_none()\n",
    "                    .label_from_df(dep_var)\n",
    "                    .databunch(bs=params['bs']))\n",
    "    print(data)\n",
    "    \n",
    "    #create fastai learner that handles the training and prediction of the neural network\n",
    "    learn = tabular_learner(data, layers=params['layers'], metrics=accuracy, ps=params['ps'], emb_szs=emb_szs, emb_drop=params['emb_drop'], callback_fns=[ShowGraph])\n",
    "    if use_GPU:\n",
    "        learn = learn.to_fp16()\n",
    "    \n",
    "    #conduct and plot learning rate range test:\n",
    "    '''\n",
    "    random_seed(123)\n",
    "    learn.lr_find()\n",
    "    fig = learn.recorder.plot(suggestion=False, return_fig=True)\n",
    "    '''\n",
    "    \n",
    "    #fit neural network on training set\n",
    "    random_seed(123)\n",
    "    learn.fit_one_cycle(params['epochs'], max_lr=params['lr'], wd=params['wd'])\n",
    "        \n",
    "    #evaluate neural network with test set\n",
    "    metrics = np.asarray(test_metrics(learner=learn, dep_var=dep_var, test_df=test, procs=preProcc, bs=params['bs']))\n",
    "    print('-'*15)\n",
    "    print('Results:')\n",
    "    print(f'Test loss: {metrics[0]}')\n",
    "    print(f'Test Accuracy: {metrics[1]}')\n",
    "    return learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create & Train Neural Network**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#definition of the categorical variables and the dependent variable\n",
    "cat_vars = ['S1', 'C1', 'S2', 'C2', 'S3', 'C3', 'S4', 'C4', 'S5', 'C5']\n",
    "\n",
    "dep_var = ['Hand']\n",
    "\n",
    "#define fastai data preparation processes\n",
    "preProcc = [Categorify]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load dataset\n",
    "train,test = load_dataset()\n",
    "\n",
    "#define the embedding dimension either through giving all variables the same dimension\n",
    "#or by calculating the dimensions with the fastai rule\n",
    "emb_szs = {}\n",
    "print('Entity Embedding Dimensions:')\n",
    "for column in test[cat_vars]:\n",
    "    n_cat = test[column].nunique()\n",
    "    emb_sz = min(600, round(1.6 * n_cat**0.56))\n",
    "    #emb_sz = 7\n",
    "    emb_szs[column] = emb_sz\n",
    "    print(f'{column}: {n_cat} -> {emb_sz}')\n",
    "params['emb_szs'] = emb_szs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cross validation\n",
    "fit_model_cv(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fit model on complete training data and test with test data\n",
    "learn = fit_model_test(train, test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
